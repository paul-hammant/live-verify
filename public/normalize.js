/*
    Copyright (C) 2025, Paul Hammant

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU Affero General Public License as
    published by the Free Software Foundation, either version 3 of the
    License, or (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU Affero General Public License for more details.

    You should have received a copy of the GNU Affero General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.
*/

/**
 * Shared text normalization and hashing functions
 * Used by both the main app and test pages
 */

/**
 * Apply document-specific normalization rules from .verification-meta.json
 * This allows document issuers to define character substitutions and regex patterns
 * @param {string} text - Text to normalize
 * @param {Object} metadata - Metadata from .verification-meta.json (optional)
 * @returns {string} Normalized text with document-specific rules applied
 */
function applyDocSpecificNorm(text, metadata) {
    if (!metadata) {
        return text;
    }

    // Import the document-specific normalization module if available
    if (typeof require !== 'undefined') {
        try {
            const docNorm = require('./doc-specific-normalization.js');
            return docNorm.applyDocumentSpecificNormalization(text, metadata);
        } catch (e) {
            // Module not available in browser, fallback to inline implementation
        }
    }

    // Browser fallback: inline implementation
    let result = text;

    // 1. Apply character normalization (compact notation: "éèêë→e àáâä→a")
    if (metadata.charNormalization) {
        const groups = metadata.charNormalization.trim().split(/\s+/);
        for (const group of groups) {
            const parts = group.split('→');
            if (parts.length === 2 && parts[1].length === 1) {
                const sourceChars = parts[0];
                const targetChar = parts[1];
                for (const sourceChar of sourceChars) {
                    const regex = new RegExp(sourceChar.replace(/[.*+?^${}()|[\]\\]/g, '\\$&'), 'g');
                    result = result.replace(regex, targetChar);
                }
            }
        }
    }

    // 2. Apply OCR normalization rules (regex patterns)
    if (metadata.ocrNormalizationRules && Array.isArray(metadata.ocrNormalizationRules)) {
        for (const rule of metadata.ocrNormalizationRules) {
            if (rule.pattern && rule.replacement) {
                try {
                    const regex = new RegExp(rule.pattern, 'g');
                    result = result.replace(regex, rule.replacement);
                } catch (e) {
                    console.error(`Invalid regex pattern: ${rule.pattern}`, e);
                }
            }
        }
    }

    return result;
}

// Text normalization function (as per the document rules)
function normalizeText(text, metadata = null) {
    // Apply document-specific normalization FIRST (before standard normalization)
    // This ensures user-typed text gets the same treatment as OCR text
    text = applyDocSpecificNorm(text, metadata);

    // Normalize Unicode characters that OCR might produce
    text = text.replace(/[\u201C\u201D\u201E]/g, '"');  // Curly double quotes → straight
    text = text.replace(/[\u2018\u2019]/g, "'");        // Curly single quotes → straight
    text = text.replace(/[\u00AB\u00BB]/g, '"');        // Angle quotes → straight double
    text = text.replace(/[\u2013\u2014]/g, '-');        // En/em dash → hyphen
    text = text.replace(/\u00A0/g, ' ');                // Non-breaking space → space
    text = text.replace(/\u2026/g, '...');              // Ellipsis → three periods

    // Split into lines
    const lines = text.split('\n');

    // Apply normalization rules to each line
    const normalizedLines = lines.map(line => {
        // Remove leading spaces
        line = line.replace(/^\s+/, '');
        // Remove leading border artifacts (OCR from registration marks/borders)
        // Common characters: | ~ ` ^ * # + = _ \ / [ ] { }
        // Examples: "| text", "~ text", "|| text", "| | text"
        line = line.replace(/^[|~`^*#+=/\\_\[\]{}]+\s*/, '');
        // Remove trailing spaces
        line = line.replace(/\s+$/, '');
        // Remove trailing border artifacts (OCR from registration marks/borders)
        // Examples: "text |", "text ~", "text ||", "text | |"
        line = line.replace(/\s*[|~`^*#+=/\\_\[\]{}]+$/, '');
        // Remove trailing single lowercase letter (OCR artifact)
        // Examples: "John Doe a", "Company Name b" -> "John Doe", "Company Name"
        // Preserves uppercase like "Appendix A", "Grade A" which are likely meaningful
        line = line.replace(/\s+[a-z]$/, '');
        // Collapse multiple spaces into single space
        line = line.replace(/\s+/g, ' ');
        return line;
    })
    .filter(line => line.length > 0); // Remove blank lines

    // Join back with newlines, no trailing newline
    return normalizedLines.join('\n');
}

// SHA-256 hash function (works in both browser and Node.js)
function sha256(text) {
    // Node.js environment (for testing)
    if (typeof require !== 'undefined' && typeof window === 'undefined') {
        const crypto = require('crypto');
        return crypto.createHash('sha256').update(text, 'utf8').digest('hex');
    }

    // Browser environment (production)
    return (async () => {
        const encoder = new TextEncoder();
        const data = encoder.encode(text);
        const hashBuffer = await crypto.subtle.digest('SHA-256', data);
        const hashArray = Array.from(new Uint8Array(hashBuffer));
        const hashHex = hashArray.map(b => b.toString(16).padStart(2, '0')).join('');
        return hashHex;
    })();
}

// Export for Node.js testing (doesn't affect browser usage)
if (typeof module !== 'undefined' && module.exports) {
    module.exports = { normalizeText, sha256, applyDocSpecificNorm };
}
